{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78097bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m187.3/187.3 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/isss11/personal-projects/ai-political-alignment/.env/lib/python3.10/site-packages (from beautifulsoup4) (4.13.1)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.13.4 soupsieve-2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c5d7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "topics = [\"Climate change, energy\", \"Cost of living\", \"Defence\", \"Foreign policy\", \"Government spending\", \"Housing\", \"Immigration\", \"Infrastructure\", \"U.S. relations, tariffs\"]\n",
    "parties = [\"Liberal\", \"Conservative\", \"New Democrat\", \"Bloc Qu√©b√©cois\", \"Green\", \"People's Party\"]\n",
    "party_ids = {\"Liberal\": 0, \"Conservative\": 1, \"New Democrat\": 2, \"Bloc Qu√©b√©cois\": 3, \"Green\": 4, \"People's Party\": 5}\n",
    "\n",
    "scraped_parties = []\n",
    "scraped_labels = []\n",
    "scraped_topics = []\n",
    "scraped_texts = []\n",
    "\n",
    "with open(\"../data/2025/platform-comparison.html\") as fp:\n",
    "    soup = BeautifulSoup(fp)\n",
    "    fetched_topics = soup.find_all(\"div\", class_=\"an-issue\")\n",
    "    \n",
    "    for topic_index, topic in enumerate(fetched_topics):\n",
    "        paragraphs = topic.find_all(\"p\")\n",
    "        \n",
    "        for party_index, party in enumerate(parties):\n",
    "            scraped_parties.append(party)\n",
    "            scraped_labels.append(party_ids[party])\n",
    "            scraped_topics.append(topics[topic_index])\n",
    "            scraped_texts.append(paragraphs[party_index].text)\n",
    "            \n",
    "df = pd.DataFrame({\"party\": scraped_parties, \"topic\": scraped_topics, \"text\": scraped_texts, \"label\": scraped_labels})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae1bab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isss11/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43/43 [00:00<00:00, 952.35 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [00:00<00:00, 816.24 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/isss11/.local/lib/python3.10/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_21953/2238691739.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 15:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.805711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.775119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.784791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.786881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.786179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "# Split dataset\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels}).map(tokenize_function, batched=True)\n",
    "test_dataset = Dataset.from_dict({\"text\": test_texts, \"label\": test_labels}).map(tokenize_function, batched=True)\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=6)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    auto_find_batch_size=True,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(\"./canadian_political_bert\")\n",
    "tokenizer.save_pretrained(\"./canadian_political_bert\")\n",
    "\n",
    "print(\"Model training complete and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2793f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 11992,  2052, 21825,  2035,  6351, 20874,  1010,  2164,  2006,\n",
      "          3919, 12495, 24168,  1012,  2027,  2052, 12992, 21134,  1006,  1041,\n",
      "          1012,  1043,  1012,  1010,  7818,  4171,  6495,  1007,  2005,  5661,\n",
      "          2008,  5547, 11768,  1998,  2000,  5326,  4550,  2943,  6786,  1012,\n",
      "          1996,  2283,  8440,  1005,  1056,  2623,  2049,  6351, 11768,  7312,\n",
      "          4539,  1010,  2021,  2758,  2009,  2052,  2224,  1996,  3000,  3820,\n",
      "          2000,  9167,  3010,  4219,  1998,  2974,  2000,  2896,  3795, 11768,\n",
      "          1012,  1996,  2283,  2052,  2036,  3749,  1037,  4171, 20438,  2005,\n",
      "          8712,  2040,  2896, 11768,  1012,  2009,  2052,  2490,  2019,  2264,\n",
      "          1011,  2225, 13117,  1998,  2052, 14300,  3934,  2107,  2004,  1048,\n",
      "          3070,  5447,  1012,  1996,  2283,  2052,  2022,  2330,  2000,  9167,\n",
      "          2075,  3514,  2013,  1996,  3417,  1997, 10888,  1998,  2038, 16970,\n",
      "          2000,  3177,  2039,  2458,  1997,  1996,  3417,  1012, 11992,  2052,\n",
      "          7221,  1996, 23642,  1997,  6315, 19873,  2046, 21938,  1998, 21825,\n",
      "          1996,  2976,  7221,  2006,  2309,  1011,  2224, 26166,  1012,   102]],\n",
      "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "5\n",
      "People's Party\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def predict_political_affiliation(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  # Move to GPU if available\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(inputs)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    print(predicted_class)\n",
    "\n",
    "    # Map class index to party\n",
    "    return parties[predicted_class]\n",
    "\n",
    "print(predict_political_affiliation(\"Conservatives would repeal all carbon pricing, including on industrial emitters. They would boost incentives (e.g., expand tax credits) for businesses that reduce emissions and to promote clean energy technologies. The party hasn't announced its carbon emissions reduction target, but says it would use the Paris Agreement to export Canadian resources and technology to lower global emissions. The party would also offer a tax incentive for manufacturers who lower emissions. It would support an east-west pipeline and would approve projects such as LNG Quebec. The party would be open to exporting oil from the Port of Churchill and has pledged to speed up development of the port. Conservatives would ban the dumping of raw sewage into waterways and repeal the federal ban on single-use plastics.\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
